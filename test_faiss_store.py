#!/usr/bin/env python3
"""
Script de prueba para FaissVectorStore
Prototipo_chatbot - TFM Vicente Caruncho
"""

import sys
import os
import time
import numpy as np
from pathlib import Path
from datetime import datetime

# AÃ±adir el directorio raÃ­z al path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_faiss_dependencies():
    """Verificar dependencias de FAISS"""
    print("ğŸ” Verificando dependencias FAISS...")
    
    try:
        import faiss
        print(f"   âœ… faiss: {faiss.__version__ if hasattr(faiss, '__version__') else 'instalado'}")
    except ImportError:
        print("   âŒ faiss: No instalado")
        print("   ğŸ’¡ Instalar con: pip install faiss-cpu")
        return False
    
    try:
        import numpy as np
        print(f"   âœ… numpy: {np.__version__}")
    except ImportError:
        print("   âŒ numpy: No instalado")
        return False
    
    return True

def test_faiss_vector_store():
    """Prueba completa del FaissVectorStore"""
    print("ğŸš€ Iniciando prueba del FaissVectorStore...")
    print("=" * 60)
    
    try:
        print("ğŸ“¦ 1. Importando mÃ³dulos...")
        
        from app.services.rag.faiss_store import (
            FaissVectorStore, 
            FaissMetrics,
            create_faiss_store,
            is_faiss_available
        )
        from app.services.rag.embeddings import embedding_service
        from app.models import DocumentChunk, DocumentMetadata
        
        print("   âœ… MÃ³dulos importados correctamente")
        
    except ImportError as e:
        print(f"   âŒ Error importando: {e}")
        return False
    
    try:
        print("\nğŸ”§ 2. Verificando disponibilidad...")
        
        # Verificar que FAISS estÃ© disponible
        if not is_faiss_available():
            print("   âŒ FAISS no disponible")
            return False
        
        print("   âœ… FAISS disponible")
        
        # Verificar que EmbeddingService estÃ© disponible
        if not embedding_service.is_available():
            print("   âŒ EmbeddingService no disponible")
            return False
        
        print("   âœ… EmbeddingService disponible")
        
    except Exception as e:
        print(f"   âŒ Error verificando servicios: {e}")
        return False
    
    try:
        print("\nğŸ—ï¸ 3. Creando FaissVectorStore de prueba...")
        
        # Crear store en directorio temporal
        test_store_path = "data/test_faiss"
        store = create_faiss_store(
            store_path=test_store_path,
            dimension=384,
            index_type="IndexFlatL2"
        )
        
        print(f"   âœ… Store creado en: {test_store_path}")
        
        # Verificar estado inicial
        stats = store.get_stats()
        print(f"   âœ… Vectores iniciales: {stats.get('total_vectors', 0)}")
        print(f"   âœ… Tipo de Ã­ndice: {stats.get('index_type', 'unknown')}")
        
    except Exception as e:
        print(f"   âŒ Error creando store: {e}")
        return False
    
    try:
        print("\nğŸ“ 4. Creando documentos de prueba...")
        
        # Crear metadatos de prueba
        test_metadata = DocumentMetadata(
            source_path="test_document.pdf",
            source_type="document",
            file_type=".pdf",
            size_bytes=1024,
            created_at=datetime.now(),
            processed_at=datetime.now(),
            checksum="test_checksum"
        )
        
        # Crear chunks de prueba
        test_texts = [
            "AdministraciÃ³n local y servicios pÃºblicos municipales",
            "TramitaciÃ³n de expedientes y licencias de actividad",
            "GestiÃ³n de padrones y registros administrativos",
            "AtenciÃ³n ciudadana y ventanilla Ãºnica",
            "Normativa municipal y ordenanzas locales",
            "Presupuestos y hacienda municipal",
            "Urbanismo y planeamiento territorial",
            "Servicios sociales y bienestar ciudadano"
        ]
        
        test_chunks = []
        for i, text in enumerate(test_texts):
            chunk = DocumentChunk(
                id=f"test-chunk-{i+1}",
                content=text,
                metadata=test_metadata,
                chunk_index=i,
                chunk_size=len(text),
                start_char=i*100,
                end_char=(i+1)*100
            )
            test_chunks.append(chunk)
        
        print(f"   âœ… {len(test_chunks)} chunks creados")
        
    except Exception as e:
        print(f"   âŒ Error creando documentos: {e}")
        return False
    
    try:
        print("\nğŸ§  5. Generando embeddings...")
        
        # Generar embeddings usando EmbeddingService
        start_time = time.time()
        embedded_chunks = embedding_service.encode_documents(test_chunks)
        embedding_time = time.time() - start_time
        
        print(f"   âœ… Embeddings generados en {embedding_time:.3f}s")
        print(f"   âœ… Chunks con embeddings: {len(embedded_chunks)}")
        
        # Verificar que tienen embeddings
        for i, chunk in enumerate(embedded_chunks[:3]):
            print(f"   âœ… Chunk {i+1}: embedding shape {np.array(chunk.embedding).shape}")
        
    except Exception as e:
        print(f"   âŒ Error generando embeddings: {e}")
        return False
    
    try:
        print("\nğŸ’¾ 6. AÃ±adiendo documentos a FAISS...")
        
        # AÃ±adir documentos al store
        start_time = time.time()
        success = store.add_documents(embedded_chunks)
        add_time = time.time() - start_time
        
        if not success:
            print("   âŒ Error aÃ±adiendo documentos")
            return False
        
        print(f"   âœ… Documentos aÃ±adidos en {add_time:.3f}s")
        
        # Verificar estado despuÃ©s de aÃ±adir
        stats = store.get_stats()
        print(f"   âœ… Total vectores: {stats.get('total_vectors', 0)}")
        print(f"   âœ… Memoria usada: {stats.get('index_size_mb', 0):.2f} MB")
        
        # Verificar distribuciÃ³n por tipo
        metrics_dict = stats.get('metrics', {})
        source_dist = metrics_dict.get('source_distribution', {})
        print(f"   âœ… DistribuciÃ³n por tipo: {source_dist}")
        
    except Exception as e:
        print(f"   âŒ Error aÃ±adiendo documentos: {e}")
        return False
    
    try:
        print("\nğŸ” 7. Probando bÃºsquedas...")
        
        # Test bÃºsqueda bÃ¡sica
        query_text = "licencias de actividad municipal"
        query_embedding = embedding_service.encode_single_text(query_text)
        
        start_time = time.time()
        results = store.search(query_embedding, k=3)
        search_time = time.time() - start_time
        
        print(f"   âœ… BÃºsqueda completada en {search_time:.3f}s")
        print(f"   âœ… Resultados encontrados: {len(results)}")
        
        # Mostrar resultados
        for i, (chunk, score) in enumerate(results):
            print(f"   ğŸ“„ Resultado {i+1}: score={score:.3f}")
            print(f"       Texto: {chunk.content[:50]}...")
            print(f"       ID: {chunk.id}")
        
    except Exception as e:
        print(f"   âŒ Error en bÃºsquedas: {e}")
        return False
    
    try:
        print("\nğŸ¯ 8. Probando filtros...")
        
        # Test bÃºsqueda con filtros
        filters = {'source_type': 'document'}
        
        start_time = time.time()
        filtered_results = store.search(query_embedding, k=3, filters=filters)
        filtered_search_time = time.time() - start_time
        
        print(f"   âœ… BÃºsqueda filtrada en {filtered_search_time:.3f}s")
        print(f"   âœ… Resultados filtrados: {len(filtered_results)}")
        
        # Verificar que los filtros funcionan
        for chunk, score in filtered_results:
            assert chunk.metadata.source_type == 'document', "Filtro no aplicado correctamente"
        
        print("   âœ… Filtros funcionando correctamente")
        
    except Exception as e:
        print(f"   âŒ Error en filtros: {e}")
        return False
    
    try:
        print("\nğŸ“Š 9. Probando mÃ©tricas y benchmarking...")
        
        # Obtener estadÃ­sticas detalladas
        stats = store.get_stats()
        metrics = stats.get('metrics', {})
        
        print("   âœ… MÃ©tricas de rendimiento:")
        print(f"      - Tiempo promedio add: {metrics.get('avg_add_time', 0):.3f}s")
        print(f"      - Tiempo promedio search: {metrics.get('avg_search_time', 0):.3f}s")
        print(f"      - Total operaciones add: {metrics.get('total_add_operations', 0)}")
        print(f"      - Total operaciones search: {metrics.get('total_search_operations', 0)}")
        print(f"      - Memoria usada: {stats.get('index_size_mb', 0):.2f} MB")
        
    except Exception as e:
        print(f"   âŒ Error obteniendo mÃ©tricas: {e}")
        return False
    
    try:
        print("\nğŸ’¾ 10. Probando persistencia...")
        
        # Crear nuevo store apuntando al mismo directorio
        store2 = FaissVectorStore(store_path=test_store_path)
        
        # Verificar que cargÃ³ los datos
        stats2 = store2.get_stats()
        print(f"   âœ… Store2 cargado con {stats2.get('total_vectors', 0)} vectores")
        
        # Verificar que puede buscar
        results2 = store2.search(query_embedding, k=2)
        print(f"   âœ… Store2 bÃºsqueda: {len(results2)} resultados")
        
        # Verificar que los resultados son consistentes
        if len(results) > 0 and len(results2) > 0:
            assert results[0][0].id == results2[0][0].id, "Resultados inconsistentes"
            print("   âœ… Persistencia funcionando correctamente")
        
    except Exception as e:
        print(f"   âŒ Error en persistencia: {e}")
        return False
    
    try:
        print("\nğŸ§ª 11. Test de rendimiento...")
        
        # Test de rendimiento con mÃ¡s documentos
        performance_chunks = []
        for i in range(50):
            chunk = DocumentChunk(
                id=f"perf-chunk-{i}",
                content=f"Documento de rendimiento nÃºmero {i} con contenido variado para testing",
                metadata=test_metadata,
                chunk_index=i,
                chunk_size=70,
                start_char=i*100,
                end_char=(i+1)*100
            )
            performance_chunks.append(chunk)
        
        # Generar embeddings
        perf_embedded = embedding_service.encode_documents(performance_chunks)
        
        # AÃ±adir al store
        start_time = time.time()
        store.add_documents(perf_embedded)
        batch_add_time = time.time() - start_time
        
        print(f"   âœ… {len(performance_chunks)} docs aÃ±adidos en {batch_add_time:.3f}s")
        print(f"   âœ… Throughput: {len(performance_chunks)/batch_add_time:.1f} docs/segundo")
        
        # Test de bÃºsquedas mÃºltiples
        queries = ["documento", "rendimiento", "testing", "contenido"]
        total_search_time = 0
        
        for query in queries:
            query_emb = embedding_service.encode_single_text(query)
            start_time = time.time()
            _ = store.search(query_emb, k=5)
            total_search_time += time.time() - start_time
        
        avg_search = total_search_time / len(queries)
        print(f"   âœ… Tiempo promedio bÃºsqueda: {avg_search:.3f}s")
        
    except Exception as e:
        print(f"   âŒ Error en test de rendimiento: {e}")
        return False
    
    print("\nğŸ‰ Â¡Todos los tests de FaissVectorStore completados exitosamente!")
    print("=" * 60)
    
    # Resumen final
    final_stats = store.get_stats()
    print("\nğŸ“Š RESUMEN FINAL:")
    print(f"âœ… Tipo de Ã­ndice: {final_stats.get('index_type', 'unknown')}")
    print(f"âœ… Total vectores: {final_stats.get('total_vectors', 0)}")
    print(f"âœ… DimensiÃ³n: {final_stats.get('dimension', 0)}")
    print(f"âœ… Memoria usada: {final_stats.get('index_size_mb', 0):.2f} MB")
    
    metrics = final_stats.get('metrics', {})
    print(f"âœ… Operaciones add: {metrics.get('total_add_operations', 0)}")
    print(f"âœ… Operaciones search: {metrics.get('total_search_operations', 0)}")
    print(f"âœ… Tiempo promedio add: {metrics.get('avg_add_time', 0):.3f}s")
    print(f"âœ… Tiempo promedio search: {metrics.get('avg_search_time', 0):.3f}s")
    
    print("\nğŸ¯ FaissVectorStore listo para producciÃ³n!")
    return True


def cleanup_test_data():
    """Limpiar datos de prueba"""
    import shutil
    test_dir = Path("data/test_faiss")
    if test_dir.exists():
        try:
            shutil.rmtree(test_dir)
            print("ğŸ§¹ Datos de prueba limpiados")
        except Exception as e:
            print(f"âš ï¸  Error limpiando: {e}")


if __name__ == "__main__":
    print("ğŸ§ª Test del FaissVectorStore - Prototipo_chatbot")
    print("=" * 60)
    
    # Verificar dependencias primero
    if not test_faiss_dependencies():
        print("\nğŸ’” No se pueden ejecutar los tests sin las dependencias")
        print("ğŸ’¡ Instalar con: pip install faiss-cpu")
        sys.exit(1)
    
    # Ejecutar tests
    try:
        success = test_faiss_vector_store()
        
        if success:
            print("\nğŸ‰ Â¡TESTS DE FAISS COMPLETADOS EXITOSAMENTE!")
            print("ğŸ‘‰ Listo para continuar con ChromaDB")
            cleanup_test_data()
            sys.exit(0)
        else:
            print("\nğŸ’” Algunos tests de FAISS fallaron")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸  Tests interrumpidos por el usuario")
        cleanup_test_data()
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ Error inesperado en tests de FAISS: {e}")
        cleanup_test_data()
        sys.exit(1) 