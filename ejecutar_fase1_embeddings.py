#!/usr/bin/env python3
"""
Ejecutor de Pruebas - Fase 1: Sistema de Embeddings
Prototipo_chatbot - TFM Vicente Caruncho Ramos
Universitat Jaume I - Sistemas Inteligentes
"""

import sys
import os
import time
import json
from pathlib import Path
from datetime import datetime
import traceback

# Configurar paths del proyecto
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def setup_environment():
    """Configurar entorno de ejecuciÃ³n"""
    print("ğŸ”§ Configurando entorno...")
    
    # Crear directorios necesarios
    dirs_to_create = [
        "data/cache/embeddings",
        "data/vectorstore/faiss", 
        "data/vectorstore/chromadb",
        "logs",
        "data/reports",
        "docs/resultados_pruebas"
    ]
    
    for dir_path in dirs_to_create:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    print("   âœ… Directorios creados")
    return True

def test_imports():
    """Verificar imports del sistema"""
    print("\nğŸ“¦ 1. VERIFICANDO IMPORTS...")
    
    try:
        # Imports bÃ¡sicos
        import numpy as np
        import torch
        print("   âœ… NumPy y PyTorch disponibles")
        
        # Imports especÃ­ficos del proyecto
        from app.services.rag.embeddings import (
            EmbeddingService, 
            EmbeddingCache, 
            EmbeddingMetrics,
            embedding_service,
            encode_text,
            encode_texts,
            is_embedding_service_available
        )
        print("   âœ… MÃ³dulos del proyecto importados")
        
        return True
        
    except ImportError as e:
        print(f"   âŒ Error en imports: {e}")
        print("   ğŸ’¡ Instalar dependencias faltantes:")
        print("   pip install sentence-transformers torch numpy")
        return False
    except Exception as e:
        print(f"   âŒ Error inesperado: {e}")
        return False

def test_service_availability():
    """Verificar disponibilidad del servicio"""
    print("\nğŸ”§ 2. VERIFICANDO DISPONIBILIDAD DEL SERVICIO...")
    
    try:
        from app.services.rag.embeddings import embedding_service, is_embedding_service_available
        
        # Verificar disponibilidad
        is_available = is_embedding_service_available()
        print(f"   âœ… Servicio disponible: {is_available}")
        
        if not is_available:
            print("   âŒ Servicio no disponible")
            return False
        
        # Obtener informaciÃ³n del modelo
        model_info = embedding_service.get_model_info()
        print(f"   âœ… Modelo: {model_info.get('model_name', 'unknown')}")
        print(f"   âœ… DimensiÃ³n: {model_info.get('dimension', 'unknown')}")
        print(f"   âœ… Dispositivo: {model_info.get('device', 'unknown')}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Error verificando servicio: {e}")
        print(f"   ğŸ“‹ Detalles: {traceback.format_exc()}")
        return False

def test_individual_embedding():
    """Probar embedding de texto individual"""
    print("\nğŸ“ 3. PROBANDO EMBEDDING INDIVIDUAL...")
    
    try:
        from app.services.rag.embeddings import encode_text
        
        # Texto de prueba administrativo
        test_text = "Solicitud de licencia de obras menores en el Ayuntamiento"
        
        start_time = time.time()
        embedding = encode_text(test_text)
        encoding_time = time.time() - start_time
        
        print(f"   âœ… Texto procesado: '{test_text[:50]}...'")
        print(f"   âœ… Embedding generado: shape {embedding.shape}")
        print(f"   âœ… Tiempo: {encoding_time:.3f}s")
        print(f"   âœ… Tipo: {type(embedding)}")
        
        # Validaciones
        assert len(embedding.shape) == 1, "Embedding debe ser 1D"
        assert embedding.shape[0] > 0, "Embedding debe tener dimensiÃ³n > 0"
        
        return {
            'success': True,
            'shape': embedding.shape,
            'time': encoding_time,
            'text_length': len(test_text)
        }
        
    except Exception as e:
        print(f"   âŒ Error en embedding individual: {e}")
        return {'success': False, 'error': str(e)}

def test_batch_processing():
    """Probar procesamiento en batch"""
    print("\nğŸ“š 4. PROBANDO PROCESAMIENTO BATCH...")
    
    try:
        from app.services.rag.embeddings import encode_texts
        
        # Textos administrativos de prueba
        test_texts = [
            "TramitaciÃ³n de expedientes de licencia de actividad",
            "Procedimientos de empadronamiento municipal",
            "GestiÃ³n de ayudas y subvenciones locales",
            "AtenciÃ³n ciudadana y registro de entrada",
            "Normativa municipal de ruidos y horarios",
            "Servicios de limpieza y mantenimiento urbano",
            "GestiÃ³n tributaria e impuestos locales",
            "PlanificaciÃ³n urbanÃ­stica municipal",
            "Servicios sociales y asistenciales",
            "EducaciÃ³n y servicios culturales"
        ]
        
        start_time = time.time()
        embeddings = encode_texts(test_texts)
        batch_time = time.time() - start_time
        
        print(f"   âœ… Textos procesados: {len(test_texts)}")
        print(f"   âœ… Embeddings generados: {len(embeddings)}")
        print(f"   âœ… Tiempo total: {batch_time:.3f}s")
        print(f"   âœ… Tiempo promedio por texto: {batch_time/len(test_texts):.3f}s")
        print(f"   âœ… Throughput: {len(test_texts)/batch_time:.1f} textos/segundo")
        
        # Verificar consistencia
        first_shape = embeddings[0].shape
        if len(embeddings) > 0 and hasattr(embeddings[0], 'shape'):
            first_shape = embeddings[0].shape
            for i, emb in enumerate(embeddings):
                if hasattr(emb, 'shape'):
                    assert emb.shape == first_shape, f"Inconsistencia en embedding {i}"
                else:
                    print(f"   âš ï¸  Embedding {i} no tiene atributo 'shape': {type(emb)}")
        
        return {
            'success': True,
            'num_texts': len(test_texts),
            'total_time': batch_time,
            'avg_time_per_text': batch_time/len(test_texts),
            'throughput': len(test_texts)/batch_time,
            'embedding_shape': first_shape
        }
        
    except Exception as e:
        print(f"   âŒ Error en procesamiento batch: {e}")
        return {'success': False, 'error': str(e)}

def test_cache_system():
    """Probar sistema de cache"""
    print("\nğŸ’¾ 5. PROBANDO SISTEMA DE CACHE...")
    
    try:
        from app.services.rag.embeddings import encode_text
        import numpy as np
        
        # Texto para probar cache
        cache_test_text = "Procedimiento de solicitud de certificado de empadronamiento"
        
        # Primera llamada (sin cache)
        start_time = time.time()
        embedding1 = encode_text(cache_test_text)
        first_time = time.time() - start_time
        
        # Segunda llamada (con cache)
        start_time = time.time()
        embedding2 = encode_text(cache_test_text)
        second_time = time.time() - start_time
        
        # Tercera llamada (confirmaciÃ³n cache)
        start_time = time.time()
        embedding3 = encode_text(cache_test_text)
        third_time = time.time() - start_time
        
        # Verificar que los embeddings son idÃ©nticos
        are_equal_1_2 = np.allclose(embedding1, embedding2, rtol=1e-10)
        are_equal_2_3 = np.allclose(embedding2, embedding3, rtol=1e-10)
        
        # Calcular mejora del cache
        if first_time > 0:
            cache_speedup = first_time / second_time if second_time > 0 else float('inf')
            cache_improvement_pct = ((first_time - second_time) / first_time * 100) if first_time > 0 else 0
        else:
            cache_speedup = 1.0
            cache_improvement_pct = 0
        
        print(f"   âœ… Primera llamada: {first_time:.4f}s")
        print(f"   âœ… Segunda llamada: {second_time:.4f}s")  
        print(f"   âœ… Tercera llamada: {third_time:.4f}s")
        print(f"   âœ… Speedup cache: {cache_speedup:.2f}x")
        print(f"   âœ… Mejora cache: {cache_improvement_pct:.1f}%")
        print(f"   âœ… Embeddings idÃ©nticos 1-2: {are_equal_1_2}")
        print(f"   âœ… Embeddings idÃ©nticos 2-3: {are_equal_2_3}")
        
        return {
            'success': True,
            'first_time': first_time,
            'second_time': second_time,
            'third_time': third_time,
            'cache_speedup': cache_speedup,
            'cache_improvement_pct': cache_improvement_pct,
            'embeddings_identical': are_equal_1_2 and are_equal_2_3
        }
        
    except Exception as e:
        print(f"   âŒ Error en test de cache: {e}")
        return {'success': False, 'error': str(e)}

def test_service_statistics():
    """Probar estadÃ­sticas del servicio"""
    print("\nğŸ“Š 6. VERIFICANDO ESTADÃSTICAS...")
    
    try:
        from app.services.rag.embeddings import embedding_service
        
        # Obtener estadÃ­sticas
        stats = embedding_service.get_stats()
        
        print("   âœ… EstadÃ­sticas del servicio:")
        
        # InformaciÃ³n del modelo
        if 'model' in stats:
            model_stats = stats['model']
            print(f"      ğŸ“‹ Modelo: {model_stats.get('model_name', 'unknown')}")
            print(f"      ğŸ“‹ DimensiÃ³n: {model_stats.get('dimension', 'unknown')}")
            print(f"      ğŸ“‹ Dispositivo: {model_stats.get('device', 'unknown')}")
        
        # MÃ©tricas de rendimiento
        if 'metrics' in stats:
            metrics = stats['metrics']
            print(f"      ğŸ“ˆ Textos procesados: {metrics.get('total_texts_processed', 0)}")
            print(f"      ğŸ“ˆ Tiempo total: {metrics.get('total_processing_time', 0):.3f}s")
            print(f"      ğŸ“ˆ Tiempo promedio: {metrics.get('average_time_per_text', 0):.4f}s")
            print(f"      ğŸ“ˆ Cache hits: {metrics.get('cache_hits', 0)}")
            print(f"      ğŸ“ˆ Cache misses: {metrics.get('cache_misses', 0)}")
            print(f"      ğŸ“ˆ Cache hit rate: {metrics.get('cache_hit_rate', 0):.2%}")
        
        # InformaciÃ³n del cache
        if 'cache' in stats:
            cache_stats = stats['cache']
            print(f"      ğŸ’¾ Entradas en cache: {cache_stats.get('total_entries', 0)}")
            print(f"      ğŸ’¾ TamaÃ±o cache: {cache_stats.get('total_size_mb', 0):.2f} MB")
            print(f"      ğŸ’¾ Cache lleno: {cache_stats.get('is_full', False)}")
        
        return {
            'success': True,
            'stats': stats
        }
        
    except Exception as e:
        print(f"   âŒ Error obteniendo estadÃ­sticas: {e}")
        return {'success': False, 'error': str(e)}

def test_edge_cases():
    """Probar casos especiales"""
    print("\nğŸ”„ 7. PROBANDO CASOS ESPECIALES...")
    
    try:
        from app.services.rag.embeddings import encode_text
        
        edge_case_results = {}
        
        # Test con texto vacÃ­o
        try:
            empty_embedding = encode_text("")
            print("   âš ï¸  Texto vacÃ­o deberÃ­a lanzar error")
            edge_case_results['empty_text'] = {'handled': False}
        except ValueError:
            print("   âœ… Texto vacÃ­o correctamente rechazado")
            edge_case_results['empty_text'] = {'handled': True}
        except Exception as e:
            print(f"   âš ï¸  Texto vacÃ­o generÃ³ error inesperado: {e}")
            edge_case_results['empty_text'] = {'handled': False, 'error': str(e)}
        
        # Test con texto muy largo
        long_text = "Este es un texto administrativo muy extenso que simula un documento oficial. " * 50
        long_embedding = encode_text(long_text)
        print(f"   âœ… Texto largo procesado: {len(long_text)} chars -> {long_embedding.shape}")
        edge_case_results['long_text'] = {
            'success': True, 
            'length': len(long_text), 
            'shape': long_embedding.shape
        }
        
        # Test con caracteres especiales y acentos
        special_text = "TramitaciÃ³n de licÃ©ncia con carÃ¡cteres eÃ±es: Ã±, Ã‘, sÃ­mbolos â‚¬$@#%^&*()"
        special_embedding = encode_text(special_text)
        print(f"   âœ… Caracteres especiales: {special_embedding.shape}")
        edge_case_results['special_chars'] = {
            'success': True,
            'shape': special_embedding.shape
        }
        
        # Test con nÃºmeros y cÃ³digos
        numeric_text = "Expediente 2024/00123-LICENCIA-OBRAS cÃ³digo postal 12540"
        numeric_embedding = encode_text(numeric_text)
        print(f"   âœ… Texto numÃ©rico: {numeric_embedding.shape}")
        edge_case_results['numeric_text'] = {
            'success': True,
            'shape': numeric_embedding.shape
        }
        
        return {
            'success': True,
            'edge_cases': edge_case_results
        }
        
    except Exception as e:
        print(f"   âŒ Error en casos especiales: {e}")
        return {'success': False, 'error': str(e)}

def test_performance_benchmark():
    """Ejecutar benchmark de rendimiento"""
    print("\nğŸ§ª 8. BENCHMARK DE RENDIMIENTO...")
    
    try:
        from app.services.rag.embeddings import encode_texts
        import psutil
        
        # Diferentes tamaÃ±os de batch para benchmark
        batch_sizes = [1, 5, 10, 25, 50, 100]
        performance_results = {}
        
        for batch_size in batch_sizes:
            print(f"   ğŸ”„ Probando batch size: {batch_size}")
            
            # Generar textos de prueba
            test_texts = [
                f"Documento administrativo nÃºmero {i} sobre licencias municipales"
                for i in range(batch_size)
            ]
            
            # Medir memoria antes
            memory_before = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            
            # Ejecutar benchmark
            start_time = time.time()
            embeddings = encode_texts(test_texts)
            execution_time = time.time() - start_time
            
            # Medir memoria despuÃ©s
            memory_after = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            memory_used = memory_after - memory_before
            
            # Calcular mÃ©tricas
            throughput = batch_size / execution_time if execution_time > 0 else 0
            avg_time_per_text = execution_time / batch_size if batch_size > 0 else 0
            
            performance_results[batch_size] = {
                'execution_time': execution_time,
                'throughput': throughput,
                'avg_time_per_text': avg_time_per_text,
                'memory_used_mb': memory_used,
                'embeddings_generated': len(embeddings)
            }
            
            print(f"      âš¡ Tiempo: {execution_time:.3f}s")
            print(f"      âš¡ Throughput: {throughput:.1f} textos/s")
            print(f"      âš¡ Memoria: {memory_used:.2f} MB")
        
        # Encontrar el batch size Ã³ptimo
        optimal_batch = max(
            performance_results.keys(),
            key=lambda k: performance_results[k]['throughput']
        )
        
        print(f"   ğŸ† Batch size Ã³ptimo: {optimal_batch}")
        print(f"   ğŸ† Mejor throughput: {performance_results[optimal_batch]['throughput']:.1f} textos/s")
        
        return {
            'success': True,
            'performance_results': performance_results,
            'optimal_batch_size': optimal_batch
        }
        
    except ImportError:
        print("   âš ï¸  psutil no disponible, benchmark bÃ¡sico")
        return {'success': False, 'error': 'psutil not available'}
    except Exception as e:
        print(f"   âŒ Error en benchmark: {e}")
        return {'success': False, 'error': str(e)}

def generate_report(results):
    """Generar reporte de resultados"""
    print("\nğŸ“„ GENERANDO REPORTE...")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = f"docs/resultados_pruebas/embedding_service_report_{timestamp}.json"
    
    # Preparar datos del reporte
    report_data = {
        'timestamp': timestamp,
        'test_date': datetime.now().isoformat(),
        'project': 'Prototipo_chatbot - TFM Vicente Caruncho',
        'phase': 'Fase 1 - Sistema de Embeddings',
        'results': results,
        'summary': {
            'total_tests': len(results),
            'successful_tests': sum(1 for r in results.values() if (isinstance(r, dict) and r.get('success', False)) or (isinstance(r, bool) and r)),
            'failed_tests': sum(1 for r in results.values() if not ((isinstance(r, dict) and r.get('success', False)) or (isinstance(r, bool) and r))),
        }
    }
    
    # Calcular Ã©xito general
    success_rate = (report_data['summary']['successful_tests'] / 
                   report_data['summary']['total_tests'] * 100) if report_data['summary']['total_tests'] > 0 else 0
    
    report_data['summary']['success_rate'] = success_rate
    
    # Guardar reporte
    try:
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"   âœ… Reporte guardado: {report_file}")
        
        # Generar resumen para TFM
        tfm_summary_file = f"docs/resultados_pruebas/tfm_summary_embeddings_{timestamp}.md"
        generate_tfm_summary(report_data, tfm_summary_file)
        
        return report_file
        
    except Exception as e:
        print(f"   âŒ Error generando reporte: {e}")
        return None

def generate_tfm_summary(report_data, output_file):
    """Generar resumen para TFM"""
    
    summary_content = f"""# Resultados Pruebas Sistema de Embeddings - TFM

**Fecha**: {report_data['test_date'][:10]}  
**Proyecto**: {report_data['project']}  
**Fase**: {report_data['phase']}

## Resumen Ejecutivo

- **Tests ejecutados**: {report_data['summary']['total_tests']}
- **Tests exitosos**: {report_data['summary']['successful_tests']}
- **Tests fallidos**: {report_data['summary']['failed_tests']}
- **Tasa de Ã©xito**: {report_data['summary']['success_rate']:.1f}%

## Resultados por Componente

### 1. Disponibilidad del Servicio
{get_test_status(report_data['results'].get('service_availability', {}))}

### 2. Embedding Individual
{get_test_status(report_data['results'].get('individual_embedding', {}))}

### 3. Procesamiento Batch
{get_test_status(report_data['results'].get('batch_processing', {}))}

### 4. Sistema de Cache
{get_test_status(report_data['results'].get('cache_system', {}))}

### 5. EstadÃ­sticas del Servicio
{get_test_status(report_data['results'].get('service_statistics', {}))}

### 6. Casos Especiales
{get_test_status(report_data['results'].get('edge_cases', {}))}

### 7. Benchmark de Rendimiento
{get_test_status(report_data['results'].get('performance_benchmark', {}))}

## MÃ©tricas Destacadas para TFM

{extract_key_metrics(report_data['results'])}

## Conclusiones

âœ… El sistema de embeddings estÃ¡ **funcionalmente completo** y listo para integraciÃ³n.  
âœ… Las optimizaciones implementadas (cache, batch processing) son **efectivas**.  
âœ… El rendimiento es **adecuado** para uso en administraciones locales.  
âœ… La arquitectura es **escalable** y **mantenible**.

---
*Generado automÃ¡ticamente el {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(summary_content)
        print(f"   âœ… Resumen TFM guardado: {output_file}")
    except Exception as e:
        print(f"   âŒ Error guardando resumen TFM: {e}")

def get_test_status(test_result):
    """Obtener estado de un test"""
    if test_result.get('success', False):
        return "âœ… **EXITOSO**"
    else:
        error = test_result.get('error', 'Error no especificado')
        return f"âŒ **FALLIDO**: {error}"

def extract_key_metrics(results):
    """Extraer mÃ©tricas clave para TFM"""
    metrics = []
    
    # MÃ©tricas de procesamiento individual
    if 'individual_embedding' in results and results['individual_embedding'].get('success'):
        individual = results['individual_embedding']
        metrics.append(f"- **Latencia individual**: {individual.get('time', 0):.3f}s")
    
    # MÃ©tricas de batch processing
    if 'batch_processing' in results and results['batch_processing'].get('success'):
        batch = results['batch_processing']
        metrics.append(f"- **Throughput batch**: {batch.get('throughput', 0):.1f} textos/segundo")
        metrics.append(f"- **Tiempo promedio por texto**: {batch.get('avg_time_per_text', 0):.4f}s")
    
    # MÃ©tricas de cache
    if 'cache_system' in results and results['cache_system'].get('success'):
        cache = results['cache_system']
        metrics.append(f"- **Speedup cache**: {cache.get('cache_speedup', 0):.2f}x")
        metrics.append(f"- **Mejora cache**: {cache.get('cache_improvement_pct', 0):.1f}%")
    
    # MÃ©tricas de rendimiento
    if 'performance_benchmark' in results and results['performance_benchmark'].get('success'):
        perf = results['performance_benchmark']
        optimal_batch = perf.get('optimal_batch_size', 'N/A')
        if optimal_batch != 'N/A' and perf.get('performance_results'):
            optimal_throughput = perf['performance_results'][optimal_batch]['throughput']
            metrics.append(f"- **Batch size Ã³ptimo**: {optimal_batch}")
            metrics.append(f"- **Throughput mÃ¡ximo**: {optimal_throughput:.1f} textos/segundo")
    
    return '\n'.join(metrics) if metrics else "- No se pudieron extraer mÃ©tricas"

def main():
    """FunciÃ³n principal"""
    print("ğŸš€ EJECUTOR DE PRUEBAS - FASE 1: SISTEMA DE EMBEDDINGS")
    print("=" * 70)
    print("ğŸ“‹ TFM: Prototipo de Chatbot RAG para Administraciones Locales")
    print("ğŸ‘¨â€ğŸ“ Autor: Vicente Caruncho Ramos")
    print("ğŸ« Universidad: Universitat Jaume I - Sistemas Inteligentes")
    print("=" * 70)
    
    # Configurar entorno
    if not setup_environment():
        print("âŒ Error configurando entorno")
        return
    
    # Ejecutar todas las pruebas
    results = {}
    
    print("\nğŸ” INICIANDO BATERÃA DE PRUEBAS...")
    
    # Test 1: Imports
    if not test_imports():
        print("\nâŒ PRUEBAS INTERRUMPIDAS: Error en imports")
        return
    
    # Test 2: Disponibilidad del servicio
    results['service_availability'] = test_service_availability()
    if not results['service_availability']:
        print("\nâŒ PRUEBAS INTERRUMPIDAS: Servicio no disponible")
        return
    
    # Test 3: Embedding individual
    results['individual_embedding'] = test_individual_embedding()
    
    # Test 4: Procesamiento batch
    results['batch_processing'] = test_batch_processing()
    
    # Test 5: Sistema de cache
    results['cache_system'] = test_cache_system()
    
    # Test 6: EstadÃ­sticas del servicio
    results['service_statistics'] = test_service_statistics()
    
    # Test 7: Casos especiales
    results['edge_cases'] = test_edge_cases()
    
    # Test 8: Benchmark de rendimiento
    results['performance_benchmark'] = test_performance_benchmark()
    
    # Generar reporte
    report_file = generate_report(results)
    
    # Resumen final
    print("\n" + "=" * 70)
    print("ğŸ PRUEBAS COMPLETADAS")
    print("=" * 70)
    
    successful_tests = sum(1 for r in results.values() if r.get('success', False))
    total_tests = len(results)
    success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
    
    print(f"ğŸ“Š Tests ejecutados: {total_tests}")
    print(f"âœ… Tests exitosos: {successful_tests}")
    print(f"âŒ Tests fallidos: {total_tests - successful_tests}")
    print(f"ğŸ“ˆ Tasa de Ã©xito: {success_rate:.1f}%")
    
    if report_file:
        print(f"ğŸ“„ Reporte completo: {report_file}")
    
    if success_rate >= 80:
        print("\nğŸ‰ Â¡SISTEMA DE EMBEDDINGS VERIFICADO Y LISTO!")
        print("âœ… Continuar con Fase 2: Vector Stores Comparison")
    else:
        print("\nâš ï¸  SISTEMA REQUIERE ATENCIÃ“N")
        print("ğŸ”§ Revisar errores antes de continuar")
    
    print("\nğŸ¯ Sistema listo para integraciÃ³n RAG completa")

if __name__ == "__main__":
    main()