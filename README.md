# ü§ñ Prototipo_chatbot

## **Sistema de Chatbot RAG para Administraciones Locales**

> **Prototipo de Chatbot Interno para Administraciones Locales Usando Modelos de Lenguaje Locales y Comparaci√≥n con OpenAI**  
> **Trabajo Final de M√°ster - Vicente Caruncho Ramos**  
> **M√°ster en Sistemas Inteligentes - Universitat Jaume I**  
> **Tutor: Rafael Berlanga Llavori**  
> **Curso 2024-2025**

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![Flask](https://img.shields.io/badge/Flask-2.3+-green.svg)
![FAISS](https://img.shields.io/badge/FAISS-1.7+-red.svg)
![ChromaDB](https://img.shields.io/badge/ChromaDB-0.4+-purple.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)
![Status](https://img.shields.io/badge/Status-89%25%20Completado-brightgreen.svg)
![TFM](https://img.shields.io/badge/TFM-Sistemas%20Inteligentes-orange.svg)

---

## üìã Descripci√≥n del Proyecto

### **Contexto y Motivaci√≥n**

Las administraciones locales espa√±olas manejan grandes vol√∫menes de informaci√≥n distribuida en m√∫ltiples fuentes: documentos oficiales, p√°ginas web, bases de datos, APIs de servicios, etc. Los ciudadanos y funcionarios necesitan acceder a esta informaci√≥n de manera eficiente, pero actualmente enfrentan:

- **Fragmentaci√≥n de informaci√≥n** en m√∫ltiples sistemas
- **Dificultad para encontrar** respuestas espec√≠ficas
- **Inconsistencias** entre diferentes fuentes
- **Procesos manuales** lentos y propensos a errores
- **Barrera t√©cnica** para consultas complejas

### **Soluci√≥n Propuesta**

Este proyecto desarrolla un **sistema conversacional basado en arquitectura RAG** (Retrieval-Augmented Generation) que permite a t√©cnicos municipales y ciudadanos consultar informaci√≥n administrativa mediante lenguaje natural, integrando m√∫ltiples fuentes de datos de forma transparente y eficiente.

### **Objetivos del TFM**

#### **Objetivo Principal**
Desarrollar y evaluar un prototipo de chatbot RAG que demuestre la viabilidad t√©cnica y econ√≥mica de implementar sistemas de IA conversacional en administraciones locales espa√±olas, comparando el rendimiento de modelos locales versus servicios cloud.

#### **Objetivos Espec√≠ficos**
1. **Dise√±ar una arquitectura RAG modular** adaptable a diferentes administraciones
2. **Implementar ingesta multimodal** de documentos administrativos (PDF, DOCX, web, APIs)
3. **Comparar emp√≠ricamente** tecnolog√≠as de vector stores (FAISS vs ChromaDB)
4. **Evaluar modelos de lenguaje** locales (Ollama) versus cloud (OpenAI)
5. **Desarrollar m√©tricas espec√≠ficas** para evaluar sistemas RAG en contexto gubernamental
6. **Crear framework reproducible** para futuras investigaciones en el sector p√∫blico

---

## ‚ú® Caracter√≠sticas Principales

### **üîç RAG Avanzado**
- **Recuperaci√≥n sem√°ntica** desde m√∫ltiples fuentes heterog√©neas
- **Embeddings optimizados** con sentence-transformers y cache LRU inteligente
- **Vector stores duales** para comparaci√≥n emp√≠rica (FAISS + ChromaDB)
- **Filtrado avanzado** por metadatos y contexto temporal
- **Ranking h√≠brido** que combina relevancia sem√°ntica y autoridad de fuente

### **‚öñÔ∏è Comparaci√≥n Dual de Modelos**
- **Modelos locales** (Ollama: llama3.2:3b, mistral:7b, gemma2:2b)
- **Modelos cloud** (OpenAI: gpt-4o, gpt-4o-mini, gpt-3.5-turbo)
- **Evaluaci√≥n autom√°tica** de respuestas con m√©tricas de calidad
- **An√°lisis de costos** y tiempo de respuesta en tiempo real
- **Dashboard comparativo** con visualizaci√≥n de resultados

### **üõ°Ô∏è Seguridad y Cumplimiento**
- **Procesamiento local** de datos sensibles para cumplimiento ENS
- **Trazabilidad completa** de consultas y respuestas
- **Audit logging** para transparencia y accountability
- **Rate limiting** y protecci√≥n contra abuso
- **Preparado para CCN-TEC 014** (Esquema Nacional de Seguridad)

### **üîß Arquitectura Modular**
- **Componentes intercambiables** para adaptaci√≥n espec√≠fica
- **Configuraci√≥n YAML** centralizada y flexible
- **APIs REST** para integraci√≥n con sistemas existentes
- **WebSocket** para chat en tiempo real
- **Docker ready** para deployment escalable

### **üìä M√©tricas y Benchmarking**
- **Framework cient√≠fico** de evaluaci√≥n reproducible
- **M√©tricas espec√≠ficas** para administraciones p√∫blicas
- **Benchmarking autom√°tico** FAISS vs ChromaDB
- **Reportes acad√©micos** en JSON y Markdown
- **Visualizaci√≥n** de resultados emp√≠ricos

### **üì• Ingesta Multimodal**
- **Documentos estructurados**: PDF, DOCX, TXT, Excel, CSV
- **Contenido web**: Scraping inteligente con rate limiting
- **APIs REST**: Conexi√≥n a servicios municipales existentes
- **Bases de datos**: Integraci√≥n SQL con m√∫ltiples SGBD
- **Procesamiento OCR** para documentos escaneados

---

## üèóÔ∏è Arquitectura del Sistema

### **Vista General**

```mermaid
graph TB
    subgraph "üåê Capa de Presentaci√≥n"
        WebUI[Interfaz Web]
        ChatUI[Chat Interface]
        AdminUI[Panel Admin]
        API[REST API]
    end
    
    subgraph "üß† Capa de Procesamiento"
        Router[Request Router]
        Auth[Autenticaci√≥n]
        
        subgraph "üì• Pipeline de Ingesta"
            DocProc[Procesador Documentos]
            WebScrap[Web Scraper]
            APIConn[Conector APIs]
            DBConn[Conector BBDD]
        end
        
        subgraph "üîç Motor RAG" 
            Embed[EmbeddingService]
            FAISS[FAISS Store]
            ChromaDB[ChromaDB Store]
            LLMService[LLM Service]
        end
        
        subgraph "üìä An√°lisis"
            Metrics[Recolector M√©tricas]
            Benchmark[Motor Benchmark]
            Comparator[Comparador Modelos]
        end
    end
    
    subgraph "üíæ Capa de Almacenamiento"
        VectorDB[(Vector Databases)]
        FileStore[(Almac√©n Archivos)]
        MetaDB[(Base Metadatos)]
        Cache[(Cache LRU)]
    end
    
    WebUI --> Router
    ChatUI --> Router
    AdminUI --> Router
    API --> Router
    
    Router --> DocProc
    Router --> WebScrap
    Router --> APIConn
    Router --> DBConn
    
    DocProc --> Embed
    WebScrap --> Embed
    APIConn --> Embed
    DBConn --> Embed
    
    Embed --> FAISS
    Embed --> ChromaDB
    FAISS --> LLMService
    ChromaDB --> LLMService
    
    LLMService --> Metrics
    Metrics --> Benchmark
    Benchmark --> Comparator
    
    Embed --> Cache
    FAISS --> VectorDB
    ChromaDB --> VectorDB
```

### **Componentes Principales**

#### **üß† EmbeddingService**
```python
# Servicio de embeddings optimizado
class EmbeddingService:
    - modelo: all-MiniLM-L6-v2 (384 dimensiones)
    - cache_lru: Optimizaci√≥n inteligente de rendimiento
    - batch_processing: Procesamiento eficiente en lotes
    - metrics: Tracking detallado para an√°lisis
    - memory_management: Gesti√≥n autom√°tica de recursos
```

#### **üóÑÔ∏è Vector Stores Duales**
```python
# FAISS - Velocidad y control
FaissVectorStore:
    - indices: IndexFlatL2, IndexIVFFlat, HNSW
    - metadatos: Gesti√≥n externa con pickle
    - optimizaci√≥n: Parameter tuning autom√°tico
    - memoria: Eficiencia m√°xima para datasets grandes

# ChromaDB - Facilidad y funcionalidad  
ChromaDBVectorStore:
    - persistencia: SQLite backend autom√°tico
    - metadatos: Integrados con queries complejas
    - filtrado: WHERE clauses nativas avanzadas
    - transacciones: ACID compliance garantizado
```

#### **ü§ñ LLM Service**
```python
# Gesti√≥n dual de modelos
LLMService:
    ollama_client:
        - modelos: llama3.2:3b, mistral:7b, gemma2:2b
        - local: Sin costos por token, m√°xima privacidad
        - latencia: Optimizada para respuestas r√°pidas
        
    openai_client:
        - modelos: gpt-4o, gpt-4o-mini, gpt-3.5-turbo  
        - cloud: Calidad state-of-the-art
        - cost_tracking: Monitoreo autom√°tico de gastos
```

---

## üöÄ Inicio R√°pido

### **Prerrequisitos**

#### **Software Necesario**
- **Python 3.9+** (recomendado 3.11)
- **Git** para clonado del repositorio
- **PowerShell** (Windows) o **Bash** (Linux/macOS)
- **Ollama** para modelos locales - [Instalar Ollama](https://ollama.ai/)
- **Cuenta OpenAI** (opcional) - [OpenAI API](https://platform.openai.com/)

#### **Recursos del Sistema**
- **RAM**: M√≠nimo 8GB, recomendado 16GB
- **Almacenamiento**: 5GB libres para modelos y datos
- **CPU**: Cualquier procesador moderno (64-bit)
- **GPU**: Opcional, aceleraci√≥n autom√°tica si disponible

### **Instalaci√≥n Paso a Paso**

#### **1. Clonar y Configurar Proyecto**
```powershell
# Clonar repositorio
git clone https://github.com/vcaruncho/prototipo_chatbot.git
cd prototipo_chatbot

# Crear y activar entorno virtual
python -m venv venv
# Windows PowerShell:
venv\Scripts\Activate.ps1
# Windows CMD:
venv\Scripts\activate.bat  
# Linux/macOS:
source venv/bin/activate

# Actualizar pip e instalar dependencias
python -m pip install --upgrade pip
pip install -r requirements.txt
```

#### **2. Configurar Variables de Entorno**
```powershell
# Copiar configuraci√≥n de ejemplo
Copy-Item .env.example .env

# Editar .env con tu configuraci√≥n preferida
# Especialmente importante si usar√°s OpenAI:
OPENAI_API_KEY=sk-tu-api-key-aqui
```

#### **3. Configurar Modelos Locales (Ollama)**
```powershell
# Instalar modelos recomendados
ollama pull llama3.2:3b     # Modelo principal (2GB)
ollama pull mistral:7b      # Modelo alternativo (4GB)  
ollama pull gemma2:2b       # Modelo ligero (1.5GB)

# Verificar instalaci√≥n
ollama list
ollama serve  # Iniciar servidor en background
```

#### **4. Verificar Instalaci√≥n**
```powershell
# Verificar dependencias cr√≠ticas
python -c "import torch, sentence_transformers, faiss, chromadb; print('‚úÖ Stack AI completo OK')"

# Ejecutar tests de componentes
python test_embedding_service.py      # Deber√≠a mostrar ‚úÖ 100% tests pasados
python test_chromadb_benchmark.py     # Verificar ChromaDB funcional
```

#### **5. Inicializar Base de Datos y Cache**
```powershell
# Crear directorios necesarios
python -c "
from pathlib import Path
dirs = ['data/vectorstore/faiss', 'data/vectorstore/chromadb', 'data/cache/embeddings', 'logs', 'data/reports']
[Path(d).mkdir(parents=True, exist_ok=True) for d in dirs]
print('‚úÖ Estructura de directorios creada')
"

# Precargar modelo de embeddings (primera ejecuci√≥n m√°s lenta)
python -c "
from app.services.rag.embeddings import embedding_service
embedding_service.warm_up()
print('‚úÖ Modelo de embeddings precargado')
"
```

#### **6. Ejecutar Aplicaci√≥n**
```powershell
# Iniciar servidor de desarrollo
python run.py

# Abrir navegador en: http://localhost:5000
# Ver√°s el dashboard principal con m√©tricas del sistema
```

### **Verificaci√≥n de Instalaci√≥n Exitosa**

Si todo est√° correcto, deber√≠as ver:
- ‚úÖ **Dashboard funcionando** en http://localhost:5000
- ‚úÖ **Logs estructurados** en `logs/prototipo_chatbot.log`
- ‚úÖ **Health check** verde en `/health`
- ‚úÖ **M√©tricas de sistema** actualiz√°ndose
- ‚úÖ **Chat interface** respondiendo (preparada para RAG)

---

## üìä Uso del Sistema

### **Interfaz Web Principal**

#### **üè† Dashboard** (`/`)
- **M√©tricas en tiempo real** del sistema
- **Estado de servicios** (Embeddings, Vector Stores, LLM)
- **Estad√≠sticas de uso** (consultas, documentos indexados)
- **Gr√°ficos de rendimiento** (tiempo de respuesta, throughput)

#### **üí¨ Chat Interface** (`/chat`)
- **Chat conversacional** con interfaz moderna
- **Historial de sesiones** persistente
- **Fuentes citadas** con transparencia completa
- **Comparaci√≥n de respuestas** (local vs cloud)
- **M√©tricas de consulta** (tiempo, tokens, costo)

#### **‚öñÔ∏è Comparaci√≥n de Modelos** (`/comparison`)
- **Testing lado a lado** de modelos locales vs cloud
- **M√©tricas detalladas** de rendimiento y calidad
- **An√°lisis de costos** en tiempo real
- **Exportaci√≥n de resultados** para an√°lisis posterior

#### **üîß Panel de Administraci√≥n** (`/admin`)
- **Gesti√≥n de documentos** indexados
- **Configuraci√≥n del sistema** en tiempo real
- **Logs del sistema** con filtrado avanzado
- **M√©tricas de uso** y estad√≠sticas detalladas

### **API REST Documentada**

#### **Endpoints Principales**
```http
# Salud del sistema
GET /api/health
Content-Type: application/json
Response: {"status": "healthy", "services": {...}, "metrics": {...}}

# Chat conversacional  
POST /api/chat
Content-Type: application/json
Body: {"message": "¬øC√≥mo tramitar una licencia?", "session_id": "uuid"}
Response: {"response": "...", "sources": [...], "metrics": {...}}

# Comparaci√≥n de modelos
POST /api/compare
Content-Type: application/json  
Body: {"query": "...", "models": ["local", "openai"]}
Response: {"local_response": {...}, "openai_response": {...}, "comparison": {...}}

# Ingesta de documentos
POST /api/ingest
Content-Type: multipart/form-data
Body: file upload + metadata
Response: {"job_id": "uuid", "status": "processing", "progress": 0}

# M√©tricas del sistema
GET /api/metrics
Response: {"embeddings": {...}, "vector_stores": {...}, "llm": {...}}
```

### **Configuraci√≥n Avanzada**

#### **Archivo .env Completo**
```bash
# ===== CONFIGURACI√ìN GENERAL =====
PROJECT_NAME=Prototipo_chatbot
PROJECT_VERSION=1.0.0
FLASK_ENV=development
FLASK_DEBUG=True
SECRET_KEY=tu-clave-secreta-segura

# ===== MODELOS DE LENGUAJE =====
# Modelos locales (Ollama)
DEFAULT_LOCAL_MODEL=llama3.2:3b
OLLAMA_BASE_URL=http://localhost:11434
AVAILABLE_LOCAL_MODELS=llama3.2:3b,mistral:7b,gemma2:2b

# Modelos OpenAI
OPENAI_API_KEY=sk-tu-api-key-aqui
DEFAULT_OPENAI_MODEL=gpt-4o-mini
AVAILABLE_OPENAI_MODELS=gpt-4o,gpt-4o-mini,gpt-3.5-turbo

# ===== EMBEDDINGS =====
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384
EMBEDDING_CACHE_DIR=data/cache/embeddings

# ===== VECTOR STORES =====
DEFAULT_VECTOR_STORE=faiss
FAISS_INDEX_PATH=data/vectorstore/faiss
CHROMADB_PATH=data/vectorstore/chromadb

# ===== RAG CONFIGURATION =====
RAG_K_DEFAULT=5
CHUNK_SIZE=500
CHUNK_OVERLAP=50
```

---

## üß™ Benchmarking y Evaluaci√≥n

### **Framework de Benchmarking Cient√≠fico**

Este proyecto incluye un framework completo para evaluaci√≥n emp√≠rica de tecnolog√≠as RAG, dise√±ado espec√≠ficamente para investigaci√≥n acad√©mica y toma de decisiones informadas.

#### **Ejecutar Comparaci√≥n Acad√©mica**
```powershell
# Benchmark completo FAISS vs ChromaDB
python comparison_faiss_vs_chromadb.py

# Resultado: 
# - data/reports/vector_stores_comparison_YYYYMMDD_HHMMSS.json
# - data/reports/vector_stores_summary_YYYYMMDD_HHMMSS.md
# - An√°lisis estad√≠stico completo con intervalos de confianza
# - Recomendaciones espec√≠ficas para administraciones locales
```

#### **M√©tricas Evaluadas**

##### **Rendimiento T√©cnico**
```python
performance_metrics = {
    "insertion_throughput": "documentos/segundo",
    "search_latency": "milisegundos/consulta", 
    "memory_efficiency": "MB/1000_documentos",
    "disk_usage": "MB total",
    "scalability": "degradaci√≥n con dataset size",
    "concurrent_performance": "usuarios simult√°neos soportados"
}
```

##### **Calidad de Resultados**
```python
quality_metrics = {
    "relevance_at_k": "% resultados relevantes en top-k",
    "mean_reciprocal_rank": "posici√≥n promedio primer resultado relevante",
    "diversity": "variedad de fuentes en resultados",
    "consistency": "estabilidad entre ejecuciones",
    "filter_effectiveness": "precisi√≥n de filtros por metadatos"
}
```

##### **Usabilidad y Mantenimiento**
```python
usability_metrics = {
    "api_complexity": "l√≠neas de c√≥digo para tareas comunes",
    "learning_curve": "tiempo para implementar casos de uso b√°sicos",
    "documentation_quality": "completitud y claridad de documentaci√≥n",
    "community_support": "actividad y recursos disponibles",
    "operational_overhead": "esfuerzo requerido para operaci√≥n"
}
```

### **Dataset de Evaluaci√≥n**

El sistema incluye un dataset cuidadosamente curado que representa casos de uso reales en administraciones locales espa√±olas:

```python
# 20 documentos representativos que cubren:
administrative_domains = [
    "Normativa y regulaciones municipales",
    "Procedimientos administrativos y tramitaci√≥n", 
    "Servicios ciudadanos y atenci√≥n al p√∫blico",
    "Gesti√≥n financiera y tributaria local",
    "Urbanismo y planificaci√≥n territorial",
    "Servicios municipales especializados"
]

# 10 consultas t√≠picas de usuarios reales:
typical_queries = [
    "licencias y permisos municipales",
    "servicios digitales administraci√≥n",
    "tramitaci√≥n expedientes ciudadanos",
    "normativa ordenanzas locales",
    "presupuestos hacienda municipal",
    # ... m√°s consultas representativas
]
```

### **Interpretaci√≥n de Resultados**

#### **Reporte Autom√°tico Generado**
```markdown
# Ejemplo de salida del benchmark:

## Resultados Principales:
- **Inserci√≥n**: FAISS 45.3 docs/seg vs ChromaDB 23.7 docs/seg (1.9x m√°s r√°pido)
- **B√∫squeda**: FAISS 12.4ms vs ChromaDB 28.7ms (2.3x m√°s r√°pido)  
- **Memoria**: FAISS 156MB vs ChromaDB 89MB (ChromaDB 43% m√°s eficiente)
- **Funcionalidad**: ChromaDB superior en filtros complejos y metadatos

## Recomendaciones:
- **Para >10K documentos**: FAISS recomendado por rendimiento
- **Para prototipado r√°pido**: ChromaDB recomendado por simplicidad
- **Para equipos sin experiencia AI**: ChromaDB m√°s amigable
- **Para producci√≥n de alta escala**: FAISS con optimizaciones
```

---

## üîß Desarrollo y Extensi√≥n

### **Estructura del Proyecto**
```
prototipo_chatbot/
‚îú‚îÄ‚îÄ üìÅ app/                          # Aplicaci√≥n principal
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ core/                     # Configuraci√≥n y utilidades
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py                  # Configuraci√≥n YAML centralizada
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logger.py                  # Logging estructurado
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ models/                   # Modelos de datos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py                # Dataclasses con validaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ routes/                   # Rutas web y API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                    # Dashboard y p√°ginas principales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.py                     # Endpoints REST documentados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.py                    # Interfaz de chat
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ admin.py                   # Panel de administraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ services/                 # L√≥gica de negocio
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ ingestion/              # Pipeline de ingesta multimodal
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document_processor.py   # PDF, DOCX, TXT, Excel
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web_scraper.py          # Scraping inteligente
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api_connector.py        # Integraci√≥n APIs REST
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database_connector.py   # Conexi√≥n BBDD SQL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ rag/                    # Motor RAG completo
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings.py           # EmbeddingService optimizado
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ faiss_store.py          # Vector store FAISS
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chromadb_store.py       # Vector store ChromaDB
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vector_store.py         # Interfaz abstracta com√∫n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_service.py             # Gesti√≥n modelos LLM
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ static/                   # Assets frontend
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ css/                    # Estilos personalizados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ js/                     # JavaScript moderno
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ images/                 # Recursos gr√°ficos
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ templates/                # Templates Jinja2
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.html                  # Template base Bootstrap 5
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.html                 # Dashboard principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.html                  # Interfaz chat
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ admin.html                 # Panel administraci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py                  # Factory Flask con blueprints
‚îú‚îÄ‚îÄ üìÅ data/                         # Datos y almacenamiento
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ vectorstore/                # Vector databases
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ faiss/                  # √çndices FAISS
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ chromadb/               # Base datos ChromaDB
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ cache/                      # Cache de embeddings
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ reports/                    # Reportes de benchmarking
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ uploads/                    # Archivos subidos por usuarios
‚îú‚îÄ‚îÄ üìÅ logs/                         # Logs estructurados
‚îú‚îÄ‚îÄ üìÅ tests/                        # Suite de tests
‚îÇ   ‚îú‚îÄ‚îÄ test_embedding_service.py      # Tests embeddings
‚îÇ   ‚îú‚îÄ‚îÄ test_chromadb_benchmark.py     # Tests ChromaDB
‚îÇ   ‚îî‚îÄ‚îÄ test_faiss_store.py           # Tests FAISS
‚îú‚îÄ‚îÄ üìÅ docs/                         # Documentaci√≥n t√©cnica
‚îÇ   ‚îú‚îÄ‚îÄ arquitectura_faiss.md          # An√°lisis FAISS para TFM
‚îÇ   ‚îú‚îÄ‚îÄ arquitectura_chromadb.md       # An√°lisis ChromaDB para TFM
‚îÇ   ‚îî‚îÄ‚îÄ guia_benchmarking.md          # Metodolog√≠a cient√≠fica
‚îú‚îÄ‚îÄ üìÑ comparison_faiss_vs_chromadb.py # Script benchmarking acad√©mico
‚îú‚îÄ‚îÄ üìÑ requirements.txt              # Dependencias Python
‚îú‚îÄ‚îÄ üìÑ .env.example                  # Template configuraci√≥n
‚îú‚îÄ‚îÄ üìÑ run.py                        # Punto de entrada
‚îî‚îÄ‚îÄ üìÑ README.md                     # Esta documentaci√≥n
```

### **A√±adir Nuevas Funcionalidades**

#### **Nuevo Vector Store**
```python
# 1. Implementar interfaz com√∫n
from app.services.rag.vector_store import VectorStore

class NuevoVectorStore(VectorStore):
    def __init__(self, config):
        # Inicializaci√≥n espec√≠fica
        pass
    
    def add_documents(self, chunks: List[DocumentChunk]) -> bool:
        # Implementar indexaci√≥n
        pass
    
    def search(self, query_embedding: np.ndarray, k: int = 5) -> List[DocumentChunk]:
        # Implementar b√∫squeda
        pass

# 2. Registrar en factory
# app/services/rag/__init__.py
vector_store_registry["nuevo"] = NuevoVectorStore

# 3. A√±adir configuraci√≥n
# .env
DEFAULT_VECTOR_STORE=nuevo
NUEVO_CONFIG_PARAM=valor
```

#### **Nuevo Modelo LLM**
```python
# 1. Extender LLMService
from app.services.llm_service import LLMService

class NuevoLLMClient:
    def generate(self, prompt: str, context: List[DocumentChunk]) -> ModelResponse:
        # Implementar generaci√≥n
        pass

# 2. Integrar en servicio principal
llm_service.register_client("nuevo_modelo", NuevoLLMClient())

# 3. Usar en chat
response = llm_service.generate_dual(
    query="consulta usuario",
    context=retrieved_chunks,
    models=["nuevo_modelo", "gpt-4o"]
)
```

#### **Nuevo Procesador de Documentos**
```python
# 1. Implementar procesador espec√≠fico
from app.services.ingestion.document_processor import DocumentProcessor

class NuevoDocumentProcessor(DocumentProcessor):
    def can_process(self, file_path: str) -> bool:
        return file_path.endswith('.nuevo_formato')
    
    def process(self, file_path: str) -> List[DocumentChunk]:
        # L√≥gica de procesamiento espec√≠fica
        pass

# 2. Registrar procesador
document_processor.register_processor(NuevoDocumentProcessor())
```

### **Testing y Calidad**

#### **Ejecutar Tests Existentes**
```powershell
# Tests unitarios de componentes
python test_embedding_service.py       # EmbeddingService completo
python test_chromadb_benchmark.py      # ChromaDB funcionalidad  
python test_faiss_store.py            # FAISS operaciones

# Verificar salud del sistema
python -c "
from app import create_app
app = create_app()
with app.test_client() as client:
    response = client.get('/api/health')
    print(f'Health Check: {response.status_code}')
    print(response.get_json())
"
```

#### **A√±adir Nuevos Tests**
```python
# tests/test_nuevo_componente.py
import pytest
from app.services.nuevo_componente import NuevoComponente

def test_nuevo_componente_inicializacion():
    componente = NuevoComponente()
    assert componente.is_available()

def test_nuevo_componente_funcionalidad():
    componente = NuevoComponente()
    resultado = componente.procesar("input_test")
    assert resultado is not None
    assert len(resultado) > 0

# Ejecutar con pytest
pytest tests/test_nuevo_componente.py -v
```

#### **Profiling y Optimizaci√≥n**
```python
# An√°lisis de rendimiento
import cProfile
import pstats

def profile_embedding_service():
    pr = cProfile.Profile()
    pr.enable()
    
    # C√≥digo a perfilar
    from app.services.rag.embeddings import embedding_service
    texts = ["texto ejemplo"] * 100
    embeddings = embedding_service.encode_batch(texts)
    
    pr.disable()
    stats = pstats.Stats(pr)
    stats.sort_stats('cumulative')
    stats.print_stats(10)

# python -c "from profile_script import profile_embedding_service; profile_embedding_service()"
```

---

## üìä Casos de Uso Espec√≠ficos

### **Para Administraciones Locales**

#### **Caso 1: Consultas Ciudadanas**
```python
# Ejemplo de consulta t√≠pica
consulta_ciudadano = """
¬øQu√© documentos necesito para solicitar una licencia de apertura 
de un peque√±o comercio en el centro hist√≥rico?
"""

# El sistema busca en:
sources_consulted = [
    "Ordenanza Municipal de Licencias",
    "Gu√≠a del Emprendedor (web municipal)", 
    "FAQ del Portal del Ciudadano",
    "Base de datos de procedimientos",
    "Normativa auton√≥mica aplicable"
]

# Respuesta contextualizada con fuentes
response = {
    "answer": "Para una licencia de apertura necesitar√°s...",
    "sources": [
        {"title": "Ordenanza de Licencias Art. 15", "confidence": 0.95},
        {"title": "Gu√≠a Portal Ciudadano", "confidence": 0.87}
    ],
    "next_steps": ["Contactar ventanilla √∫nica", "Revisar normativa espec√≠fica"]
}
```

#### **Caso 2: Consultas T√©cnicas Internas**
```python
# Consulta de funcionario municipal
consulta_funcionario = """
¬øCu√°l es el procedimiento para modificar una licencia urban√≠stica 
ya concedida cuando hay cambio de actividad?
"""

# B√∫squeda en documentaci√≥n t√©cnica avanzada
specialized_sources = [
    "Manual de Procedimientos Internos",
    "Jurisprudencia administrativa reciente",
    "Circulares de la Consejer√≠a de Urbanismo",
    "Casos similares resueltos (base de datos)",
    "Normativa t√©cnica edificaci√≥n"
]

# Respuesta con detalle t√©cnico y referencias normativas
```

#### **Caso 3: An√°lisis Comparativo**
```python
# Comparaci√≥n de respuestas modelo local vs cloud
comparison_result = {
    "query": "Procedimiento sancionador en materia de ruidos",
    "local_model": {
        "model": "llama3.2:3b",
        "response_time": "2.3s",
        "cost": "‚Ç¨0.00",
        "answer": "Respuesta detallada...",
        "quality_score": 8.2
    },
    "cloud_model": {
        "model": "gpt-4o-mini", 
        "response_time": "1.1s",
        "cost": "‚Ç¨0.003",
        "answer": "Respuesta alternativa...",
        "quality_score": 9.1
    },
    "recommendation": "Cloud model para consultas complejas, local para consultas rutinarias"
}
```

### **Para Investigadores**

#### **Reproducir Experimentos**
```powershell
# Configuraci√≥n determin√≠stica para reproducibilidad
export PYTHONHASHSEED=42
export CUDA_DETERMINISTIC=1

# Ejecutar benchmark con configuraci√≥n acad√©mica
python comparison_faiss_vs_chromadb.py --config=academic --seed=42 --iterations=10

# Analizar resultados con estad√≠sticas
python analyze_benchmark_results.py data/reports/latest_comparison.json
```

#### **Extender Dataset de Evaluaci√≥n**
```python
# A√±adir nuevos dominios de evaluaci√≥n
new_evaluation_domains = {
    "salud_publica": [
        "Protocolo COVID-19 en centros municipales",
        "Normativa sanidad alimentaria restaurantes",
        # ... m√°s documentos espec√≠ficos
    ],
    "medio_ambiente": [
        "Ordenanza gesti√≥n residuos municipales", 
        "Plan sostenibilidad energ√©tica local",
        # ... documentos ambientales
    ]
}

# Integrar en benchmark
benchmark_config.update_domains(new_evaluation_domains)
```

### **Para Desarrolladores**

#### **Integraci√≥n con Sistemas Existentes**
```python
# API REST para integraci√≥n
import requests

# Consultar desde sistema externo
response = requests.post('http://localhost:5000/api/chat', json={
    'message': 'Consulta desde sistema externo',
    'session_id': 'sistema_gestion_municipal_001',
    'metadata': {
        'user_role': 'funcionario',
        'department': 'urbanismo'
    }
})

result = response.json()
print(f"Respuesta: {result['response']}")
print(f"Fuentes: {result['sources']}")
```

#### **Webhook para Notificaciones**
```python
# Notificar actualizaciones de documentos
webhook_payload = {
    'event': 'document_updated',
    'document_id': 'ordenanza_municipal_v2.pdf',
    'changes': ['Art√≠culo 15 modificado', 'Nuevo Anexo III'],
    'requires_reindexing': True
}

requests.post('http://localhost:5000/api/webhooks/document_update', 
              json=webhook_payload)
```

---

## üöÄ Deployment y Producci√≥n

### **Deployment Local (Desarrollo)**
```powershell
# Configuraci√≥n de desarrollo
$env:FLASK_ENV="development"
$env:FLASK_DEBUG="True"
python run.py
```

### **Deployment con Docker**
```dockerfile
# Dockerfile (preparado para implementar)
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .
EXPOSE 5000

CMD ["gunicorn", "--bind", "0.0.0.0:5000", "run:app"]
```

```yaml
# docker-compose.yml (preparado)
version: '3.8'
services:
  chatbot:
    build: .
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
      - DATABASE_URL=postgresql://user:pass@db:5432/chatbot
    volumes:
      - ./data:/app/data
    depends_on:
      - db
      - redis
  
  db:
    image: postgres:15
    environment:
      POSTGRES_DB: chatbot
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  redis:
    image: redis:7-alpine
    
volumes:
  postgres_data:
```

### **Deployment Azure (Preparado)**
```yaml
# azure-pipelines.yml (preparado para CI/CD)
trigger:
- main

pool:
  vmImage: 'ubuntu-latest'

steps:
- task: UsePythonVersion@0
  inputs:
    versionSpec: '3.11'
  displayName: 'Use Python 3.11'

- script: |
    pip install -r requirements.txt
    python -m pytest tests/ -v
  displayName: 'Run tests'

- task: AzureWebApp@1
  inputs:
    azureSubscription: 'azure-subscription'
    appName: 'prototipo-chatbot'
    package: '.'
```

### **Configuraci√≥n Producci√≥n**
```bash
# .env.production
FLASK_ENV=production
FLASK_DEBUG=False
SECRET_KEY=clave-super-segura-produccion

# Base de datos PostgreSQL
DATABASE_URL=postgresql://user:pass@servidor:5432/chatbot_prod

# Redis para cache distribuido  
REDIS_URL=redis://servidor:6379/0

# Configuraci√≥n seguridad
CORS_ORIGINS=https://ayuntamiento.es,https://admin.ayuntamiento.es
RATE_LIMIT_GLOBAL=5000/hour
RATE_LIMIT_CHAT=100/hour

# Monitoreo
SENTRY_DSN=https://sentry-dsn-aqui
LOG_LEVEL=INFO
```

---

## üìà Monitoreo y Observabilidad

### **M√©tricas del Sistema**
```python
# M√©tricas autom√°ticas incluidas
system_metrics = {
    "health": {
        "status": "healthy/degraded/unhealthy",
        "uptime_seconds": 0,
        "last_restart": "timestamp"
    },
    "performance": {
        "requests_per_minute": 0,
        "avg_response_time_ms": 0,
        "error_rate_percent": 0,
        "active_sessions": 0
    },
    "resources": {
        "memory_usage_mb": 0,
        "cpu_usage_percent": 0,
        "disk_usage_gb": 0,
        "gpu_memory_mb": 0  # Si disponible
    },
    "ai_services": {
        "embedding_cache_hit_rate": 0,
        "vector_store_size_mb": 0,
        "llm_tokens_per_minute": 0,
        "cost_per_hour_usd": 0
    }
}
```

### **Alertas Configurables**
```yaml
# config/alerts.yml (preparado)
alerts:
  high_error_rate:
    condition: "error_rate > 5%"
    action: "email_admin"
    
  high_response_time:
    condition: "avg_response_time > 5000ms"
    action: "slack_notification"
    
  low_disk_space:
    condition: "disk_usage > 90%"
    action: "email_admin"
    
  embedding_service_down:
    condition: "embedding_service.status != healthy"
    action: "immediate_notification"
```

### **Dashboard de M√©tricas**
Acceso en `/admin/metrics` con visualizaci√≥n en tiempo real de:
- üìä **Gr√°ficos de rendimiento** (Chart.js)
- üéØ **KPIs principales** del sistema
- üìà **Tendencias hist√≥ricas** de uso
- üö® **Alertas activas** y su estado
- üí∞ **Costos estimados** de operaci√≥n

---

## ü§ù Contribuir al Proyecto

### **Para Estudiantes e Investigadores**

#### **√Åreas de Contribuci√≥n**
1. **Nuevos vector stores** (Pinecone, Weaviate, Qdrant)
2. **Modelos de embedding** (multilingual, domain-specific)
3. **M√©tricas de evaluaci√≥n** espec√≠ficas para sector p√∫blico
4. **Datasets especializados** por dominio administrativo
5. **Optimizaciones de rendimiento** para hardware espec√≠fico

#### **Proceso de Contribuci√≥n**
```powershell
# 1. Fork del repositorio
git clone https://github.com/tu-usuario/prototipo_chatbot.git
cd prototipo_chatbot

# 2. Crear rama para feature
git checkout -b feature/nueva-funcionalidad

# 3. Implementar y testear
# ... desarrollo ...
python -m pytest tests/ -v

# 4. Commit y push
git add .
git commit -m "feat: descripci√≥n clara del cambio"
git push origin feature/nueva-funcionalidad

# 5. Crear Pull Request con:
# - Descripci√≥n clara del cambio
# - Tests que pasen
# - Documentaci√≥n actualizada
# - Ejemplo de uso si aplica
```

### **Para Administraciones Locales**

#### **Personalizaci√≥n para tu Ayuntamiento**
```python
# config/municipio_config.yml
municipio:
  nombre: "Ayuntamiento de Tu Ciudad"
  logo: "static/images/escudo_municipal.png"
  colores:
    primario: "#003366"    # Azul institucional
    secundario: "#66CC00"  # Verde sostenible
  
  dominios_especializados:
    - "normativa_local"
    - "servicios_ciudadanos" 
    - "tramites_especificos"
    
  fuentes_datos:
    sede_electronica: "https://sede.tuciudad.es"
    portal_transparencia: "https://transparencia.tuciudad.es"
    normativa: "https://normativa.tuciudad.es"
```

#### **Casos de Uso Sugeridos**
1. **Consultas ciudadanas frecuentes** - Automatizaci√≥n primer nivel
2. **Soporte t√©cnico interno** - Ayuda a funcionarios
3. **An√°lisis de normativa** - B√∫squeda en legislaci√≥n compleja
4. **Gesti√≥n documental** - Indexaci√≥n autom√°tica de expedientes
5. **Atenci√≥n multiidioma** - Soporte comunidades locales

---

## üìö Recursos y Referencias

### **Documentaci√≥n T√©cnica**
- üìñ **[Arquitectura FAISS](docs/arquitectura_faiss.md)** - An√°lisis t√©cnico completo
- üìñ **[Arquitectura ChromaDB](docs/arquitectura_chromadb.md)** - Comparaci√≥n detallada
- üìñ **[Gu√≠a de Benchmarking](docs/guia_benchmarking.md)** - Metodolog√≠a cient√≠fica
- üîß **[API Reference](http://localhost:5000/api/docs)** - Documentaci√≥n interactiva

### **Papers y Referencias Acad√©micas**
```bibtex
@misc{caruncho2025chatbot,
  title={Prototipo de Chatbot Interno para Administraciones Locales: 
         Comparaci√≥n Emp√≠rica de Modelos Locales vs Cloud},
  author={Caruncho Ramos, Vicente},
  year={2025},
  school={Universitat Jaume I},
  type={Trabajo Final de M√°ster},
  note={M√°ster en Sistemas Inteligentes}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}
```

### **Tecnolog√≠as Utilizadas**
- ü§ñ **[sentence-transformers](https://www.sbert.net/)** - Embeddings sem√°nticos
- üîç **[FAISS](https://faiss.ai/)** - Vector similarity search
- üóÑÔ∏è **[ChromaDB](https://www.trychroma.com/)** - Vector database
- üåê **[Flask](https://flask.palletsprojects.com/)** - Web framework
- üé® **[Bootstrap 5](https://getbootstrap.com/)** - UI framework
- ü§ñ **[Ollama](https://ollama.ai/)** - Local LLM runtime
- ‚òÅÔ∏è **[OpenAI API](https://platform.openai.com/)** - Cloud LLM service

### **Comunidad y Soporte**
- üí¨ **Discussions**: Issues y mejoras en GitHub
- üìß **Email**: vcaruncho@uji.es (autor del TFM)
- üê¶ **Actualizaciones**: Seguir repositorio para cambios
- üìä **Benchmarks**: Contribuir con nuevos datasets y m√©tricas

---

## üìÑ Licencia y Atribuci√≥n

### **Licencia MIT**
```
MIT License

Copyright (c) 2025 Vicente Caruncho Ramos

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

### **Cita Acad√©mica**
Si utilizas este proyecto en investigaci√≥n acad√©mica, por favor cita:

```
Caruncho Ramos, V. (2025). Prototipo de Chatbot Interno para Administraciones 
Locales Usando Modelos de Lenguaje Locales y Comparaci√≥n con OpenAI. 
Trabajo Final de M√°ster, M√°ster en Sistemas Inteligentes, 
Universitat Jaume I, Espa√±a.
```

### **Agradecimientos**
- **Rafael Berlanga Llavori** - Tutor del TFM y gu√≠a t√©cnica
- **Universitat Jaume I** - M√°ster en Sistemas Inteligentes
- **Comunidad open-source** - Desarrolladores de las librer√≠as utilizadas
- **Administraciones locales** - Casos de uso y requisitos reales

---

## üéØ Estado Actual y Roadmap

### **Estado Actual: 89% Completado** ‚úÖ
- ‚úÖ **Sistema RAG core funcional** con dual vector stores
- ‚úÖ **Framework de benchmarking cient√≠fico** implementado
- ‚úÖ **Documentaci√≥n acad√©mica completa** para TFM
- ‚úÖ **Interface web profesional** con UX optimizada
- ‚úÖ **Pipeline de ingesta multimodal** robusta y escalable
- üîÑ **Integraci√≥n LLM dual** (75% completado)

### **Pr√≥ximos Hitos** üöÄ
1. **Completar integraci√≥n Ollama + OpenAI** (Esta semana)
2. **Ejecutar benchmarking acad√©mico completo** (Esta semana)  
3. **Finalizar memoria TFM** (Pr√≥ximas 2 semanas)
4. **Defensa del TFM** con demo en vivo

### **Extensiones Futuras** üîÆ
- ‚òÅÔ∏è **Deployment Azure/AWS** para demostraci√≥n cloud
- üõ°Ô∏è **Seguridad avanzada** con autenticaci√≥n y autorizaci√≥n
- üìä **Dashboard analytics** con m√©tricas en tiempo real
- üåê **API GraphQL** para consultas complejas
- ü§ñ **M√°s modelos LLM** (Claude, Gemini, modelos especializados)
- üåç **Soporte multiidioma** para comunidades diversas

---

**üìä Este README documenta un sistema RAG completo, funcional y listo para investigaci√≥n acad√©mica y aplicaci√≥n pr√°ctica en administraciones locales espa√±olas.**

**üéì Desarrollado como TFM en M√°ster de Sistemas Inteligentes - Universitat Jaume I**  
**üë®‚Äçüíª Vicente Caruncho Ramos - 2025**