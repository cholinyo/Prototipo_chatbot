# Arquitectura ChromaDB para Prototipo_chatbot TFM

## üéØ **An√°lisis Estrat√©gico de ChromaDB**

### **¬øQu√© es ChromaDB?**
ChromaDB es una base de datos vectorial open-source dise√±ada espec√≠ficamente para aplicaciones de AI y sistemas RAG (Retrieval-Augmented Generation). Se caracteriza por su simplicidad de uso, capacidad de ejecutarse tanto en memoria como en modo persistente, y su integraci√≥n nativa con modelos de embeddings.

### **Caracter√≠sticas Principales**
```
üîπ Base de datos vectorial especializada
üîπ Open-source con licencia Apache 2.0
üîπ API simple e intuitiva
üîπ Soporte nativo para metadatos complejos
üîπ Filtrado avanzado por atributos
üîπ Modo in-memory y persistente
üîπ Integraci√≥n con sentence-transformers
üîπ Arquitectura cliente/servidor opcional
```

## üìä **Comparativa: ChromaDB vs FAISS**

### **Ventajas de ChromaDB**
```
‚úÖ FACILIDAD DE USO:
   ‚Ä¢ API m√°s intuitiva y menos c√≥digo
   ‚Ä¢ Gesti√≥n autom√°tica de metadatos
   ‚Ä¢ No requiere mapeos manuales ID->vector

‚úÖ FUNCIONALIDADES AVANZADAS:
   ‚Ä¢ Filtrado nativo por metadatos
   ‚Ä¢ Queries complejas con WHERE clauses
   ‚Ä¢ Soporte para m√∫ltiples colecciones
   ‚Ä¢ Versionado autom√°tico de datos

‚úÖ PERSISTENCIA:
   ‚Ä¢ Base de datos real con SQLite backend
   ‚Ä¢ Transacciones ACID
   ‚Ä¢ Recuperaci√≥n autom√°tica ante fallos
   ‚Ä¢ Backup y restore integrados

‚úÖ FLEXIBILIDAD:
   ‚Ä¢ M√∫ltiples funciones de distancia
   ‚Ä¢ Embeddings functions personalizables
   ‚Ä¢ Metadatos estructurados y no estructurados
   ‚Ä¢ APIs REST y Python nativas
```

### **Desventajas de ChromaDB**
```
‚ùå RENDIMIENTO:
   ‚Ä¢ Menor velocidad que FAISS en datasets grandes
   ‚Ä¢ Overhead de base de datos relacional
   ‚Ä¢ Mayor uso de memoria para metadatos

‚ùå ESCALABILIDAD:
   ‚Ä¢ Limitaciones con millones de vectores
   ‚Ä¢ SQLite como bottleneck potencial
   ‚Ä¢ Modo distribuido a√∫n en desarrollo

‚ùå CONTROL:
   ‚Ä¢ Menos control sobre algoritmos de indexaci√≥n
   ‚Ä¢ Optimizaciones limitadas vs FAISS
   ‚Ä¢ Dependencia de decisiones del proyecto upstream
```

## üèóÔ∏è **Arquitectura T√©cnica ChromaDB**

### **Estructura Interna**
```
üóÑÔ∏è ChromaDB Database Structure:
‚îú‚îÄ‚îÄ Collections (equivalente a "tablas")
‚îÇ   ‚îú‚îÄ‚îÄ documents/ (contenido textual)
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/ (vectores 384D)
‚îÇ   ‚îú‚îÄ‚îÄ metadatas/ (informaci√≥n estructurada)
‚îÇ   ‚îî‚îÄ‚îÄ ids/ (identificadores √∫nicos)
‚îÇ
‚îú‚îÄ‚îÄ SQLite Backend
‚îÇ   ‚îú‚îÄ‚îÄ collection_metadata
‚îÇ   ‚îú‚îÄ‚îÄ embedding_metadata  
‚îÇ   ‚îú‚îÄ‚îÄ segment_metadata
‚îÇ   ‚îî‚îÄ‚îÄ index_metadata
‚îÇ
‚îî‚îÄ‚îÄ Vector Index
    ‚îú‚îÄ‚îÄ HNSW (por defecto)
    ‚îú‚îÄ‚îÄ Brute Force (peque√±os datasets)
    ‚îî‚îÄ‚îÄ Custom indexes (futuro)
```

### **Modelo de Datos Propuesto**
```python
# Colecci√≥n Principal: "prototipo_documents"
{
    "ids": ["doc_123_chunk_5", "web_456_chunk_2", ...],
    
    "documents": [
        "Texto del fragmento de licencias municipales...",
        "Informaci√≥n web sobre tramitaci√≥n...",
        ...
    ],
    
    "embeddings": [
        [0.1, -0.3, 0.7, ...],  # 384 dimensiones
        [0.2, 0.1, -0.4, ...],  # Vector 2
        ...
    ],
    
    "metadatas": [
        {
            # Metadatos de DocumentMetadata
            "source_path": "/docs/ordenanza_municipal.pdf",
            "source_type": "document",
            "file_type": ".pdf", 
            "size_bytes": 156847,
            "created_at": "2025-08-04T18:30:00Z",
            "processed_at": "2025-08-04T18:35:00Z",
            "checksum": "a1b2c3d4e5f6...",
            "title": "Ordenanza Municipal de Licencias",
            
            # Metadatos de DocumentChunk
            "chunk_id": "doc_123_chunk_5",
            "chunk_index": 5,
            "chunk_size": 856,
            "start_char": 2340,
            "end_char": 3196,
            "page_number": 12,
            "section_title": "Licencias de Actividad",
            
            # Metadatos espec√≠ficos para filtrado
            "department": "urbanismo",
            "document_category": "normativa",
            "language": "es",
            "publication_year": 2024,
            "last_updated": "2025-01-15T10:00:00Z",
            "relevance_score": 0.95,
            "content_type": "regulation"
        },
        {
            # Chunk de contenido web
            "source_path": "https://ayuntamiento.es/licencias",
            "source_type": "web",
            "url": "https://ayuntamiento.es/licencias",
            "title": "Gu√≠a Online de Licencias",
            "scraped_at": "2025-08-04T15:45:00Z",
            "chunk_id": "web_456_chunk_2",
            "content_type": "guide",
            "department": "urbanismo",
            "last_verified": "2025-07-30T12:00:00Z"
        }
    ]
}
```

## üéØ **Estrategias de Organizaci√≥n**

### **Opci√≥n A: Colecci√≥n √önica (Recomendado para TFM)**
```python
# Una sola colecci√≥n: "prototipo_documents"
collection = client.create_collection(
    name="prototipo_documents",
    metadata={
        "description": "Todos los documentos del prototipo",
        "embedding_model": "all-MiniLM-L6-v2",
        "created_for": "TFM_Vicente_Caruncho"
    }
)

# Ventajas:
‚úÖ B√∫squeda cross-domain (encuentra relaciones entre tipos)
‚úÖ Comparaci√≥n directa con FAISS (mismo dataset)
‚úÖ Filtrado flexible por metadatos
‚úÖ Gesti√≥n simplificada
‚úÖ An√°lisis acad√©mico m√°s limpio
```

### **Opci√≥n B: M√∫ltiples Colecciones (Casos Espec√≠ficos)**
```python
# Colecciones separadas por tipo de fuente
collections = {
    "official_documents": client.create_collection("official_documents"),
    "web_content": client.create_collection("web_content"), 
    "api_data": client.create_collection("api_data"),
    "database_content": client.create_collection("database_content")
}

# Casos de uso:
- Diferentes modelos de embedding por tipo
- Requisitos de seguridad espec√≠ficos
- Optimizaciones por dominio
- Separaci√≥n por nivel de confianza
```

## üîß **Implementaci√≥n T√©cnica**

### **Configuraci√≥n Optimizada**
```python
import chromadb
from chromadb.config import Settings

# Configuraci√≥n para desarrollo (persistente)
client = chromadb.PersistentClient(
    path="data/vectorstore/chromadb",
    settings=Settings(
        # Optimizaciones de rendimiento
        anonymized_telemetry=False,
        allow_reset=True,
        
        # Configuraci√≥n de indexing
        hnsw_construction_ef=200,        # Calidad construcci√≥n
        hnsw_search_ef=100,              # Calidad b√∫squeda
        hnsw_M=16,                       # Conexiones por nodo
        
        # Configuraci√≥n de memoria
        persist_directory="data/vectorstore/chromadb",
        
        # Configuraci√≥n de logging
        chroma_server_cors_allow_origins=["*"],
        chroma_server_host="localhost",
        chroma_server_http_port=8000
    )
)

# Crear colecci√≥n con configuraci√≥n espec√≠fica
collection = client.create_collection(
    name="prototipo_documents",
    metadata={
        "hnsw:space": "cosine",          # Funci√≥n de distancia
        "hnsw:construction_ef": 200,
        "hnsw:M": 16,
        "description": "Documentos administrativos para RAG",
        "embedding_model": "all-MiniLM-L6-v2",
        "dimension": 384,
        "created_at": "2025-08-04T18:00:00Z",
        "tfm_author": "Vicente Caruncho Ramos"
    }
)
```

### **Pipeline de Indexaci√≥n**
```python
def add_documents_to_chromadb(chunks: List[DocumentChunk]):
    """Pipeline optimizado para a√±adir documentos"""
    
    # 1. Preparar datos para ChromaDB
    ids = []
    documents = []
    embeddings = []
    metadatas = []
    
    for chunk in chunks:
        # IDs √∫nicos
        ids.append(chunk.id or str(uuid.uuid4()))
        
        # Contenido textual
        documents.append(chunk.content)
        
        # Embeddings (generar si no existen)
        if chunk.embedding is None:
            embedding = embedding_service.encode_single_text(chunk.content)
        else:
            embedding = chunk.embedding
        embeddings.append(embedding.tolist())
        
        # Metadatos completos
        metadata = {
            # DocumentMetadata
            "source_path": chunk.metadata.source_path,
            "source_type": chunk.metadata.source_type,
            "file_type": chunk.metadata.file_type,
            "size_bytes": chunk.metadata.size_bytes,
            "created_at": chunk.metadata.created_at.isoformat(),
            "processed_at": chunk.metadata.processed_at.isoformat(),
            "checksum": chunk.metadata.checksum,
            "title": chunk.metadata.title or "",
            
            # DocumentChunk espec√≠ficos
            "chunk_id": chunk.id,
            "chunk_index": chunk.chunk_index,
            "chunk_size": chunk.chunk_size,
            "start_char": chunk.start_char,
            "end_char": chunk.end_char,
            
            # Campos para filtrado
            "timestamp": datetime.now().isoformat(),
            "word_count": len(chunk.content.split()),
            "char_count": len(chunk.content)
        }
        
        # A√±adir metadatos opcionales
        if hasattr(chunk.metadata, 'language') and chunk.metadata.language:
            metadata["language"] = chunk.metadata.language
        if hasattr(chunk.metadata, 'url') and chunk.metadata.url:
            metadata["url"] = chunk.metadata.url
            
        metadatas.append(metadata)
    
    # 2. Inserci√≥n en lotes (recomendado para rendimiento)
    batch_size = 100
    for i in range(0, len(ids), batch_size):
        batch_end = min(i + batch_size, len(ids))
        
        collection.add(
            ids=ids[i:batch_end],
            documents=documents[i:batch_end],
            embeddings=embeddings[i:batch_end],
            metadatas=metadatas[i:batch_end]
        )
    
    return True
```

### **Pipeline de B√∫squeda Avanzada**
```python
def search_chromadb(query: str, k: int = 5, filters: Dict = None):
    """B√∫squeda avanzada con filtros y ranking"""
    
    # 1. Generar embedding de consulta
    query_embedding = embedding_service.encode_single_text(query)
    
    # 2. Construir filtros WHERE
    where_clause = {}
    if filters:
        for key, value in filters.items():
            if isinstance(value, list):
                where_clause[key] = {"$in": value}
            elif isinstance(value, dict) and "range" in value:
                where_clause[key] = {
                    "$gte": value["range"][0],
                    "$lte": value["range"][1]
                }
            else:
                where_clause[key] = {"$eq": value}
    
    # 3. Ejecutar b√∫squeda
    results = collection.query(
        query_embeddings=[query_embedding.tolist()],
        n_results=k * 2,  # Obtener m√°s para post-filtrado
        where=where_clause,
        include=["documents", "metadatas", "distances"]
    )
    
    # 4. Post-procesamiento y ranking
    chunks = []
    if results['documents'] and len(results['documents'][0]) > 0:
        documents = results['documents'][0]
        metadatas = results['metadatas'][0]
        distances = results['distances'][0]
        
        for i, (doc_text, metadata, distance) in enumerate(zip(documents, metadatas, distances)):
            # Reconstruir DocumentChunk
            doc_metadata = DocumentMetadata(
                source_path=metadata["source_path"],
                source_type=metadata["source_type"],
                file_type=metadata["file_type"],
                size_bytes=metadata["size_bytes"],
                created_at=datetime.fromisoformat(metadata["created_at"]),
                processed_at=datetime.fromisoformat(metadata["processed_at"]),
                checksum=metadata["checksum"],
                title=metadata.get("title", "")
            )
            
            chunk = DocumentChunk(
                id=metadata["chunk_id"],
                content=doc_text,
                metadata=doc_metadata,
                chunk_index=metadata["chunk_index"],
                chunk_size=metadata["chunk_size"],
                start_char=metadata["start_char"],
                end_char=metadata["end_char"]
            )
            
            # A√±adir informaci√≥n de relevancia
            chunk.similarity_score = 1 - distance  # Convertir distancia a score
            chunk.rank = i + 1
            
            chunks.append(chunk)
    
    return chunks[:k]  # Devolver solo los k mejores
```

## üìä **Casos de Uso para Administraciones Locales**

### **1. B√∫squeda Cross-Domain**
```python
# Encontrar informaci√≥n sobre "licencias" en todos los tipos de fuente
results = search_chromadb(
    query="tramitaci√≥n licencias municipales",
    k=10,
    filters=None  # Sin filtros = busca en todo
)

# Resultado t√≠pico:
# - Chunk 1: PDF oficial "Ordenanza de Licencias" (score: 0.95)
# - Chunk 2: P√°gina web "Gu√≠a ciudadano" (score: 0.89) 
# - Chunk 3: API response "Procedimientos" (score: 0.87)
# - Chunk 4: BBDD "Hist√≥rico tramitaciones" (score: 0.82)
```

### **2. B√∫squeda Filtrada por Departamento**
```python
# Solo informaci√≥n de urbanismo
urbanismo_results = search_chromadb(
    query="permisos construcci√≥n",
    k=5,
    filters={"department": "urbanismo"}
)

# Solo documentos oficiales recientes
oficiales_recientes = search_chromadb(
    query="nueva normativa municipal",
    k=3,
    filters={
        "source_type": "document",
        "publication_year": {"range": [2024, 2025]}
    }
)
```

### **3. B√∫squeda Temporal**
```python
# Informaci√≥n actualizada en los √∫ltimos 6 meses
from datetime import datetime, timedelta
recent_date = (datetime.now() - timedelta(days=180)).isoformat()

recent_info = search_chromadb(
    query="cambios procedimientos administrativos",
    k=8,
    filters={
        "last_updated": {"range": [recent_date, datetime.now().isoformat()]}
    }
)
```

### **4. B√∫squeda por Nivel de Confianza**
```python
# Solo fuentes oficiales (alta confianza)
official_sources = search_chromadb(
    query="requisitos documentaci√≥n ciudadanos",
    k=5,
    filters={
        "source_type": {"$in": ["document", "database"]},
        "content_type": "regulation"
    }
)

# Incluir gu√≠as ciudadanas (confianza media)
citizen_guides = search_chromadb(
    query="c√≥mo solicitar certificados",
    k=10,
    filters={
        "content_type": {"$in": ["regulation", "guide", "faq"]}
    }
)
```

## üéì **Beneficios para el TFM**

### **Ventajas Acad√©micas de ChromaDB**
```
üìä PARA INVESTIGACI√ìN:
‚úÖ Metadatos ricos para an√°lisis estad√≠stico
‚úÖ Queries SQL-like para investigaci√≥n
‚úÖ Trazabilidad completa de documentos
‚úÖ Versionado autom√°tico de cambios

üìä PARA COMPARACI√ìN:
‚úÖ API m√°s simple = menos variables confusas
‚úÖ Resultados m√°s interpretables
‚úÖ Filtrado nativo vs post-procesamiento
‚úÖ Gesti√≥n autom√°tica de IDs

üìä PARA PRODUCCI√ìN:
‚úÖ Base de datos real vs archivos
‚úÖ Transacciones ACID
‚úÖ Backup/restore integrado
‚úÖ API REST para integraci√≥n web
```

### **M√©tricas Espec√≠ficas ChromaDB**
```python
# M√©tricas de rendimiento
{
    "insertion_throughput": "docs/second",
    "search_latency": "ms/query", 
    "memory_efficiency": "MB/1000_docs",
    "disk_usage": "MB total",
    
    # M√©tricas de funcionalidad
    "metadata_query_support": "boolean",
    "complex_filter_support": "boolean", 
    "transaction_support": "boolean",
    "backup_restore_support": "boolean",
    
    # M√©tricas de escalabilidad
    "max_vectors_tested": "integer",
    "concurrent_users_supported": "integer",
    "collection_management_overhead": "ms"
}
```

### **Casos de Estudio Propuestos**
```
üî¨ EXPERIMENTO 1: Rendimiento vs Funcionalidad
   ‚Ä¢ Comparar velocidad FAISS vs facilidad ChromaDB
   ‚Ä¢ Medir overhead de metadatos complejos
   ‚Ä¢ Evaluar trade-offs desarrollo vs performance

üî¨ EXPERIMENTO 2: Calidad de Resultados
   ‚Ä¢ Comparar precisi√≥n con/sin filtros de metadatos
   ‚Ä¢ Evaluar relevancia contextual por tipo de fuente
   ‚Ä¢ Medir impacto de normalizaci√≥n sem√°ntica

üî¨ EXPERIMENTO 3: Escalabilidad Pr√°ctica
   ‚Ä¢ Testing con datasets crecientes (1K, 10K, 100K docs)
   ‚Ä¢ Evaluaci√≥n de degradaci√≥n de performance
   ‚Ä¢ An√°lisis de l√≠mites pr√°cticos para administraciones
```

## üéØ **Recomendaciones para el TFM**

### **Implementaci√≥n Sugerida**
1. **Usar ChromaDB para prototipo inicial** - API m√°s simple, desarrollo m√°s r√°pido
2. **Colecci√≥n √∫nica con filtros** - M√°xima flexibilidad para comparaci√≥n
3. **Metadatos ricos** - Aprovechar capacidad diferencial vs FAISS
4. **Benchmark exhaustivo** - Medir trade-offs funcionalidad vs rendimiento

### **An√°lisis Acad√©mico Recomendado**
1. **Comparaci√≥n cuantitativa** - Velocidad, memoria, throughput
2. **Comparaci√≥n cualitativa** - Facilidad desarrollo, mantenibilidad
3. **Casos de uso espec√≠ficos** - Cu√°ndo elegir cada tecnolog√≠a
4. **Proyecci√≥n futura** - Escalabilidad a largo plazo

### **Contribuci√≥n Cient√≠fica**
- **Framework de evaluaci√≥n** para vector stores en administraciones
- **M√©tricas espec√≠ficas** para sistemas RAG gubernamentales  
- **An√°lisis emp√≠rico** FAISS vs ChromaDB en casos reales
- **Buenas pr√°cticas** para implementaci√≥n en sector p√∫blico

---

**Esta arquitectura ChromaDB proporciona la base t√©cnica s√≥lida necesaria para tu an√°lisis comparativo en el TFM, combinando funcionalidad avanzada con capacidad de evaluaci√≥n acad√©mica rigurosa.**